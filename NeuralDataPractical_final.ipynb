{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJQOkfwQEGof"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "\n",
        "# Load and parse the MATLAB .mat file\n",
        "def load_mat_file(filename):\n",
        "    \"\"\"\n",
        "    Load a MATLAB .mat file and convert nested MATLAB structures to Python dictionaries.\n",
        "\n",
        "    Parameters:\n",
        "    - filename: Path to the .mat file\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary with the loaded data\n",
        "    \"\"\"\n",
        "    def _mat_to_dict(obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return [_mat_to_dict(o) for o in obj] if obj.dtype == object else obj\n",
        "        elif hasattr(obj, '_fieldnames'):\n",
        "            return {field: _mat_to_dict(getattr(obj, field)) for field in obj._fieldnames}\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    mat_data = loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
        "    return {key: _mat_to_dict(value) for key, value in mat_data.items() if not key.startswith('__')}\n",
        "\n",
        "# Plot raster of spike times across all stimuli for a specific neuron\n",
        "def plot_raster(parsed_data, neuron_index, stimlabels, line_width=2.5, tick_height=0.9):\n",
        "    \"\"\"\n",
        "    Generate raster plots showing spike times for a specific neuron across all stimuli.\n",
        "\n",
        "    Parameters:\n",
        "    - parsed_data: Loaded and parsed data from the .mat file\n",
        "    - neuron_index: Index of the neuron to plot\n",
        "    - line_width: Width of spike lines in the raster plot\n",
        "    - tick_height: Height of spike ticks in the raster plot\n",
        "    \"\"\"\n",
        "    neuron = parsed_data['alldata'][neuron_index]\n",
        "    colors = ['red', 'green', 'blue', 'black']\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    trial_counter = 0\n",
        "\n",
        "    for stim_idx, stimulus in enumerate(neuron['data']):\n",
        "        color = colors[stim_idx]\n",
        "        for trial in stimulus['sweep']:\n",
        "            plt.vlines(trial['spikes'], trial_counter + 0.5 - tick_height/2, trial_counter + 0.5 + tick_height/2, color=color, linewidth=line_width)\n",
        "            trial_counter += 1\n",
        "\n",
        "    # Add legend-like text box in the top right corner\n",
        "    #legend_text = \"\".join([f\"{stimlabels[i]}\\n\" for i in range(len(neuron['data']))])\n",
        "    #colors_list = [colors(i) for i in range(len(neuron['data']))]\n",
        "\n",
        "    # Add color-coded text\n",
        "    for i, stimlabel in enumerate(stimlabels):\n",
        "        color = colors[i]\n",
        "        plt.text(1.02, 0.95 - i * 0.05, stimlabel, transform=plt.gca().transAxes, color=color, fontsize=15, verticalalignment='top')\n",
        "\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Trial')\n",
        "    plt.title(f'Neuron {neuron_index} - Raster Plot Across All Stimuli')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Convert spike times to activity matrix using histogram binning\n",
        "def spike_times_to_activity_matrix(parsed_data, neuron_index, bin_size=1, max_time=1200):\n",
        "    \"\"\"\n",
        "    Convert spike times into an activity matrix using histogram binning.\n",
        "\n",
        "    Parameters:\n",
        "    - parsed_data: Loaded and parsed data\n",
        "    - neuron_index: Index of the neuron to analyze\n",
        "    - bin_size: Size of time bins (in ms)\n",
        "    - max_time: Maximum time duration to consider (in ms)\n",
        "\n",
        "    Returns:\n",
        "    - activity_matrix: Binary matrix representing spike activity per bin\n",
        "    - trial_counts: Number of trials per stimulus\n",
        "    \"\"\"\n",
        "    neuron_data = parsed_data['alldata'][neuron_index]['data']\n",
        "    all_trials = [trial['spikes'] for stimulus in neuron_data for trial in stimulus['sweep']]\n",
        "\n",
        "    num_trials = len(all_trials)\n",
        "    num_bins = max_time // bin_size\n",
        "    bin_edges = np.arange(0, max_time + bin_size, bin_size)\n",
        "\n",
        "    activity_matrix = np.zeros((num_trials, num_bins))\n",
        "\n",
        "    for trial_idx, trial in enumerate(all_trials):\n",
        "        spike_times = np.array(trial, ndmin=1)\n",
        "        activity_matrix[trial_idx], _ = np.histogram(spike_times, bins=bin_edges)\n",
        "\n",
        "    return activity_matrix, [len(stimulus['sweep']) for stimulus in neuron_data]\n",
        "\n",
        "# Perform PCA on activity matrix\n",
        "def neural_coding_pca(data):\n",
        "    \"\"\"\n",
        "    Perform Principal Component Analysis (PCA) on the activity matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - data: 2D NumPy array (trials x time bins)\n",
        "\n",
        "    Returns:\n",
        "    - eigenvals: Eigenvalues of principal components\n",
        "    - eigenvecs: Eigenvectors (principal components)\n",
        "    - transformed_data: Data projected into principal component space\n",
        "    \"\"\"\n",
        "    total_spikes = np.sum(data)\n",
        "    num_trials = data.shape[0]\n",
        "    norm_factor = total_spikes / num_trials if num_trials > 0 else 0\n",
        "\n",
        "    if norm_factor == 0:\n",
        "        return 0, 0, data  # No spikes present\n",
        "\n",
        "    normalized_data = data / norm_factor\n",
        "    centered_data = normalized_data - np.mean(normalized_data, axis=1, keepdims=True)\n",
        "\n",
        "    covariance_matrix = np.cov(centered_data, rowvar=False)\n",
        "    eigenvals, eigenvecs = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    sorted_indices = np.argsort(eigenvals)[::-1]\n",
        "    eigenvals = eigenvals[sorted_indices]\n",
        "    eigenvecs = eigenvecs[:, sorted_indices]\n",
        "\n",
        "    transformed_data = np.dot(centered_data, eigenvecs)\n",
        "\n",
        "    return eigenvals, eigenvecs, transformed_data\n",
        "\n",
        "# Classify neural responses and visualize the PCA space\n",
        "def classify_and_plot(transformed_data, trial_counts, num_pc_to_use, stimlabels):\n",
        "    \"\"\"\n",
        "    Classify neural responses based on PCA-transformed data and visualize the results.\n",
        "\n",
        "    Parameters:\n",
        "    - transformed_data: A 2D array where each row is a trial and each column is a principal component.\n",
        "    - trial_counts: A list with the number of trials for each stimulus.\n",
        "    - num_pc_to_use: The number of principal components to use for the classification.\n",
        "    \"\"\"\n",
        "\n",
        "    # Import ListedColormap to create our own color map later for plotting.\n",
        "    from matplotlib.colors import ListedColormap\n",
        "\n",
        "    # Create an array 'allstimuli' that contains the label for each trial.\n",
        "    # For example, if trial_counts is [5, 7], then this will create an array:\n",
        "    # [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "    allstimuli = np.concatenate([\n",
        "        np.full(count, stim) for stim, count in enumerate(trial_counts)\n",
        "    ])\n",
        "\n",
        "    # Extract the first two principal components (columns) for 2D plotting.\n",
        "    PC1 = transformed_data[:, 0]  # First principal component (x-axis)\n",
        "    PC2 = transformed_data[:, 1]  # Second principal component (y-axis)\n",
        "\n",
        "    # Define colors for each stimulus. Make sure the number of colors is at least the number of stimuli.\n",
        "    custom_colors = ['red', 'green', 'blue', 'black']\n",
        "\n",
        "    # Create a new figure with a specific size (width 8 inches, height 6 inches).\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Create a scatter plot of the data points using PC1 and PC2.\n",
        "    # Each point is colored based on its stimulus label.\n",
        "    plt.scatter(PC1, PC2, c=[custom_colors[stim] for stim in allstimuli], edgecolor='k')\n",
        "\n",
        "    # Label the x-axis and y-axis.\n",
        "    plt.xlabel('PC1', fontsize=16)\n",
        "    plt.ylabel('PC2', fontsize=16)\n",
        "    plt.tick_params(labelsize=14)  # Set tick label font size\n",
        "\n",
        "    # Create an instance of the Linear Discriminant Analysis (LDA) classifier.\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "    # Train the LDA classifier using the first 'num_pc_to_use' principal components.\n",
        "    lda.fit(transformed_data[:, :num_pc_to_use], allstimuli)\n",
        "\n",
        "    # Define the boundaries for a grid that will cover our plot area.\n",
        "    # We add a margin of 1 unit to the minimum and maximum values.\n",
        "    x_min, x_max = PC1.min() - 1, PC1.max() + 1\n",
        "    y_min, y_max = PC2.min() - 1, PC2.max() + 1\n",
        "\n",
        "    # Create a grid of points over the defined range (200 points along each axis).\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
        "\n",
        "    # Combine the grid points into a 2D array where each row is a point (x, y).\n",
        "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    # If we are using more than 2 principal components, we need to add extra dimensions.\n",
        "    # Since we can only plot in 2D, we use the average value for the extra dimensions.\n",
        "    if num_pc_to_use > 2:\n",
        "        # Calculate the average values of the additional dimensions (from the 3rd to the selected one).\n",
        "        extra_dims = np.mean(transformed_data[:, 2:num_pc_to_use], axis=0)\n",
        "        # For each grid point, append these average values so that the input has the correct dimensions.\n",
        "        grid_points = np.hstack([grid_points, np.tile(extra_dims, (grid_points.shape[0], 1))])\n",
        "\n",
        "    # Predict the class (stimulus) for each point in the grid using the trained LDA.\n",
        "    Z = lda.predict(grid_points[:, :num_pc_to_use])\n",
        "    # Reshape the predictions to match the shape of the grid for plotting.\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Create a custom colormap using our defined colors (only as many as there are stimuli).\n",
        "    cmap = ListedColormap(custom_colors[:len(trial_counts)])\n",
        "\n",
        "    # Plot the decision boundaries by coloring the grid according to predicted classes.\n",
        "    # The 'alpha' value makes this layer semi-transparent.\n",
        "    plt.contourf(xx, yy, Z, alpha=0.2, cmap=cmap)\n",
        "\n",
        "    # Predict the classes for the original data points to calculate accuracy.\n",
        "    predictions = lda.predict(transformed_data[:, :num_pc_to_use])\n",
        "    accuracy = np.mean(predictions == allstimuli) * 100  # Convert to percentage.\n",
        "\n",
        "    # Set the plot title to show the classification accuracy.\n",
        "    plt.title(f'Classification Accuracy = {accuracy:.2f}%', fontsize=16)\n",
        "\n",
        "    # Create a custom legend: for each stimulus, make a marker with the correct color.\n",
        "    handles = [plt.Line2D([0], [0], marker='o', color='w',\n",
        "                            markerfacecolor=custom_colors[i], markersize=10,\n",
        "                            label=f'{stimlabels[i]}') for i in range(len(trial_counts))]\n",
        "    plt.legend(handles=handles, title=\"Stimuli\", fontsize=14)\n",
        "\n",
        "    # Finally, display the plot.\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "IR8i6QjhN9lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from google's copy\n",
        "data_path = 'data_1ms_res.mat'\n",
        "parsed_data = load_mat_file(data_path)\n",
        "\n",
        "# Plot raster of a chosen neuron\n",
        "# Plot for different neurons to visualize interesting responses\n",
        "# each row is a trial, and different stimulus classes are color coded.\n",
        "neuron_index = 2\n",
        "\n",
        "stimlabels = [str(parsed_data['alldata'][neuron_index]['data'][stimi]['stim'][0]) \\\n",
        "                  for stimi in range(len(parsed_data['alldata'][neuron_index]['data']))]\n",
        "\n",
        "\n",
        "plot_raster(parsed_data, neuron_index=neuron_index, stimlabels=stimlabels)\n"
      ],
      "metadata": {
        "id": "BQ7krlfWEckk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert spike times to a matrix for further processing.\n",
        "# Below select bin size and see how that affects how data is represented.\n",
        "\n",
        "neuron_index = 2\n",
        "bin_size = 10\n",
        "activity_matrix, trial_counts = spike_times_to_activity_matrix(parsed_data, neuron_index=neuron_index, bin_size=bin_size, max_time=1200)\n",
        "\n",
        "# Plot the activity matrix using pcolormesh with grayscale\n",
        "plt.figure(figsize=(25, 8))\n",
        "plt.pcolormesh(activity_matrix, cmap='gray')\n",
        "\n",
        "# Add horizontal dashed lines to indicate stimulus boundaries\n",
        "cumulative_trials = np.cumsum(trial_counts)\n",
        "for line in cumulative_trials[:-1]:  # Exclude the last cumulative value as it's the total\n",
        "    plt.axhline(line, color='red', linestyle='--')\n",
        "\n",
        "plt.xlabel('Time (ms)')\n",
        "plt.ylabel('Trial')\n",
        "plt.title('Activity Matrix for Neuron 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wCjJgObRFiE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the code below performs PCA in the matrix calculated above.\n",
        "# in the figure below you can see how the variance of the data is distributed along the principal components\n",
        "\n",
        "eigenvals, eigenvecs, transformed_data = neural_coding_pca(activity_matrix)\n",
        "\n",
        "total_variance = np.sum(np.abs(eigenvals))\n",
        "explained_variance = (eigenvals / total_variance) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(explained_variance, '-o')\n",
        "plt.xlabel('Principal Component', fontsize=16)\n",
        "plt.ylabel('% Explained Variance', fontsize=16)\n",
        "plt.gca().tick_params(labelsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AG476CcpFkIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize PC weights alongside their associated time bins\n",
        "# See that the bins with higher variance will tend to be the ones with higher weights in the first PC\n",
        "\n",
        "# Select the PC you want to look, 1st PC starts at 0\n",
        "pc_i = 0\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# GridSpec layout for PC weights and activity matrix\n",
        "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n",
        "\n",
        "nbins = len(eigenvecs[:, 0])\n",
        "\n",
        "# Plot the user-defined PC\n",
        "ax = plt.subplot(gs[0])\n",
        "ax.plot(np.arange(nbins) + 0.5, eigenvecs[:, pc_i])\n",
        "ax.set_xlim(0, len(eigenvecs[:, pc_i]))\n",
        "ax.set_ylabel(f'PC{pc_i + 1}')\n",
        "\n",
        "# Plot Activity Matrix\n",
        "ax_activity = plt.subplot(gs[1])\n",
        "\n",
        "# Aligning the pcolormesh with the PCs\n",
        "extent = [0, len(eigenvecs[:, 0]), 0, activity_matrix.shape[0]]\n",
        "im = ax_activity.imshow(activity_matrix, cmap='gray', aspect='auto', extent=extent)\n",
        "\n",
        "# Add horizontal dashed lines to indicate stimulus boundaries\n",
        "cumulative_trials = np.cumsum(trial_counts)\n",
        "for line in cumulative_trials[:-1]:  # Exclude the last cumulative value as it's the total\n",
        "    plt.axhline(line, color='red', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fucteRPlFm_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the projection of the activity matrix onto the principal components\n",
        "# This helps to observe how the trials are represented in the new PCA space\n",
        "\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "num_pc_to_plot = 3  # Number of principal components to visualize\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Plot the PCA-transformed data using pcolormesh\n",
        "plt.pcolormesh(transformed_data[:, :num_pc_to_plot], cmap='Reds')\n",
        "\n",
        "# Add horizontal dashed lines to indicate stimulus boundaries\n",
        "cumulative_trials = np.cumsum(trial_counts)\n",
        "for line in cumulative_trials[:-1]:  # Exclude the last cumulative value as it's the total\n",
        "    plt.axhline(line, color='red', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4N7rA7APFpGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_pc_to_use = 2\n",
        "\n",
        "\n",
        "x = transformed_data[:, :num_pc_to_use].copy()\n",
        "\n",
        "classify_and_plot(x, trial_counts, num_pc_to_use, stimlabels=stimlabels)"
      ],
      "metadata": {
        "id": "t8bAgHCtFun0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_kuDTpEFxZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}